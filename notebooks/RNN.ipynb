{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import sys, os\n",
    "scr_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(scr_dir)\n",
    "\n",
    "from preprocess_tf import data_pipe\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = 'C://Users/gilbe/Documents/aifi-bootcamp'\n",
    "\"\"\"\n",
    "df = pd.read_csv(f'{ROOT_PATH}/data/aapl.csv')\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv(f'{ROOT_PATH}/data/aapl.csv')\n",
    "df['Unnamed: 0'] = pd.to_datetime(df['Unnamed: 0'])\n",
    "df.set_index('Unnamed: 0', inplace=True)\n",
    "df.index.rename('Date', inplace=True)\n",
    "# df.rename(columns={'Unnamed: 0', 'Date'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['4. close']].iloc[:, :10].plot(figsize=(15, 6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurent Neural Networks (RNN)\n",
    "Recurrent Neural Networks take the time dimension into accout by introducing a recursive connection with a time delay of -1. Keras implements RNN with the class called SimpleRNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"figures/rnn.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data\n",
    "Train model on 10 stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:, :10]\n",
    "df.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layered_rnn(\n",
    "    units=20, \n",
    "    input_shape=1, \n",
    "    output_shape=1, \n",
    "    learning_rate=0.01\n",
    "):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.SimpleRNN(\n",
    "        units,\n",
    "        return_sequences=True,\n",
    "        input_shape=[None, input_shape])\n",
    "             )\n",
    "    \n",
    "    model.add(tf.keras.layers.SimpleRNN(units))\n",
    "    model.add(tf.keras.layers.Dense(output_shape))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate),\n",
    "        loss=tf.keras.losses.Huber(),\n",
    "        metrics=['mae', 'mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model):\n",
    "    metrics_df = pd.DataFrame()\n",
    "\n",
    "    optim_param_dict = {}\n",
    "\n",
    "    for c in df.columns:\n",
    "        optim_param = pd.DataFrame()\n",
    "        if df.loc[:, c].isnull().sum()/len(df) < 0.5:\n",
    "            df.loc[:, c].plot(title=f'{c}');\n",
    "            plt.show();\n",
    "            print(c)\n",
    "            print(df[c].shape)\n",
    "            \n",
    "            first_valid = df.loc[:, c].first_valid_index()\n",
    "            \n",
    "            data_dict = data_pipe(\n",
    "                df.loc[first_valid:, c].values.reshape(-1, 1), \n",
    "                use_tf_data=False,\n",
    "                use_transformer=True\n",
    "            )\n",
    "\n",
    "            xtrain, ytrain, xval, yval, xtest, ytest = (\n",
    "                data_dict['xtrain'], data_dict['ytrain'], \n",
    "                data_dict['xval'], data_dict['yval'],  \n",
    "                data_dict['xtest'], data_dict['ytest']\n",
    "            )\n",
    "\n",
    "            num_outputs = ytrain.shape[-1]\n",
    "            hyper_lstm = None\n",
    "            model = None\n",
    "            model = two_layered_rnn()\n",
    "\n",
    "            history = model.fit(xtrain,\n",
    "                            ytrain,\n",
    "                            batch_size=128,\n",
    "                            epochs=20,\n",
    "                            validation_data=(xval, yval),\n",
    "                            verbose=1)\n",
    "            \n",
    "            pd.DataFrame(history.history).plot(figsize=(8, 5), grid=True)\n",
    "            plt.gca().set_ylim(0, 500)\n",
    "            plt.show();\n",
    "\n",
    "            print('#' * 50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = two_layered_rnn()\n",
    "training_loop(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gated Recurrent Networks\n",
    "\n",
    "RNNs suffer from exploding or vanishing gradients. RNNs can have a hard time to learn long term dependencies.\n",
    "\n",
    "**Solutions**:\n",
    "* Exploding gradients can be addressed by gradient clipping\n",
    "* Vanishing gradients can be addressed by gater recurrent units\n",
    "\n",
    "\n",
    "\n",
    "**Examples of gated recurrent units**:\n",
    "* Long Short Term Memory Networks (LSTM)\n",
    "* Gated Recurrent Unit (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"lstm.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layered_lstm(units=20, input_shape=1, output_shape=1, learning_rate=0.01):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.LSTM(\n",
    "        units,\n",
    "        return_sequences=True,\n",
    "        input_shape=[None, input_shape])\n",
    "             )\n",
    "    \n",
    "    model.add(tf.keras.layers.LSTM(units))\n",
    "    model.add(tf.keras.layers.Dense(output_shape))\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate),\n",
    "        loss=tf.keras.losses.Huber(),\n",
    "        metrics=['mae', 'mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = two_layered_lstm()\n",
    "training_loop(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
